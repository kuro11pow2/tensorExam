{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import datetime\n",
    "from glob import iglob\n",
    "import time\n",
    "# import attention\n",
    "from collections import deque\n",
    "import pickle\n",
    "import pyreader\n",
    "import numpy as np\n",
    "import csv\n",
    "from batchmake import Batcher\n",
    "import pprint\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22669\n"
     ]
    }
   ],
   "source": [
    "datas= 'data_samples/'\n",
    "vocabulary = 'vocab.csv'\n",
    "vocabs = []\n",
    "with open(vocabulary, 'r', newline='', encoding='utf-8') as vocab:\n",
    "    words = csv.reader(vocab)\n",
    "    for word in words:\n",
    "        vocabs.append(word)\n",
    "print(len(vocabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(?, 5, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "hidden_size=32\n",
    "sequence=5\n",
    "embedding_dim=50\n",
    "attention_size = 50\n",
    "batch_size=16\n",
    "vocab_size=len(vocabs)\n",
    "grucell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size)\n",
    "X = tf.placeholder(tf.int32, [None, sequence], name='inputs_xdata')\n",
    "# Y = tf.placeholder(tf.float32, [None, sequence], name='targets_ydata')\n",
    "Y = tf.placeholder(tf.int32, [None, sequence], name='targets_ydata')\n",
    "seq_len = tf.placeholder(tf.int32, [None], name='seq_len')\n",
    "\n",
    "embedding_variable = tf.Variable(tf.random_uniform([vocab_size, embedding_dim],-1.0,1.0), trainable=True)\n",
    "# inputs_ = tf.transpose(X)\n",
    "batch_embedded = tf.nn.embedding_lookup(embedding_variable, X)\n",
    "\n",
    "print(batch_embedded)\n",
    "with tf.variable_scope('RNN'):\n",
    "    outputs, states = tf.nn.dynamic_rnn(grucell,\n",
    "                                        inputs=batch_embedded,\n",
    "                                        sequence_length=seq_len,\n",
    "                                        dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'RNN/rnn/transpose:0' shape=(?, 5, 32) dtype=float32>,\n",
       " LSTMStateTuple(c=<tf.Tensor 'RNN/rnn/while/Exit_2:0' shape=(?, 32) dtype=float32>, h=<tf.Tensor 'RNN/rnn/while/Exit_3:0' shape=(?, 32) dtype=float32>))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs,states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.einsum('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_for_fc = tf.reshape(outputs, [-1, hidden_size])\n",
    "outputs = tf.contrib.layers.fully_connected(X_for_fc, vocab_size, activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(16, 5, 22669) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = tf.reshape(outputs, [batch_size, sequence, vocab_size])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'targets_ydata:0' shape=(?, 5) dtype=int32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = tf.ones([batch_size, sequence])\n",
    "\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "    logits=outputs, targets=Y, weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name_queue = tf.train.string_input_producer(['inputs'])\n",
    "reader = tf.TFRecordReader()\n",
    "_, single_x = reader.read(file_name_queue)\n",
    "\n",
    "context_features = {\n",
    "    \"length\": tf.FixedLenFeature([], dtype=tf.int64)\n",
    "}\n",
    "sequence_features = {\n",
    "    \"tokens\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "    \"labels\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "\n",
    "context_parsed, sequence_parsed = tf.parse_single_sequence_example(serialized=single_x,\n",
    "                                 context_features=context_features,\n",
    "                                 sequence_features=sequence_features\n",
    "                                )\n",
    "batch_seq, batch_x, batch_y = tf.train.batch(tensors=[context_parsed['length'],sequence_parsed['tokens'],sequence_parsed['labels']],\n",
    "                                                     batch_size=batch_size, \n",
    "                                                     capacity=5000,\n",
    "                                                     num_threads=1,\n",
    "                                             dynamic_pad=True\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start learning!\n",
      "0 start\n",
      " 100 : loss 6.16494607925415 acc 0\n",
      " 200 : loss 6.080910682678223 acc 0\n",
      " 300 : loss 4.800240993499756 acc 0\n",
      " 400 : loss 5.179551124572754 acc 0\n",
      " 500 : loss 5.307797908782959 acc 0\n",
      " 600 : loss 4.920200347900391 acc 0\n",
      " 700 : loss 5.766247749328613 acc 0\n",
      " 800 : loss 6.080294132232666 acc 0\n",
      " 900 : loss 4.814537048339844 acc 0\n",
      " 1000 : loss 5.6472697257995605 acc 0\n",
      " 1100 : loss 5.105912208557129 acc 0\n",
      " 1200 : loss 5.140685081481934 acc 0\n",
      " 1300 : loss 3.7921271324157715 acc 0\n",
      " 1400 : loss 6.111734867095947 acc 0\n",
      " 1500 : loss 4.88701057434082 acc 0\n",
      " 1600 : loss 4.413029193878174 acc 0\n",
      " 1700 : loss 4.571654319763184 acc 0\n",
      " 1800 : loss 5.0042314529418945 acc 0\n",
      " 1900 : loss 4.040004730224609 acc 0\n",
      " 2000 : loss 4.054974555969238 acc 0\n",
      " 2100 : loss 4.527651786804199 acc 0\n",
      " 2200 : loss 4.9951043128967285 acc 0\n",
      " 2300 : loss 4.15425968170166 acc 0\n",
      " 2400 : loss 6.330731391906738 acc 0\n",
      " 2500 : loss 4.727242946624756 acc 0\n",
      " 2600 : loss 2.779005527496338 acc 0\n",
      " 2700 : loss 4.159807205200195 acc 0\n",
      " 2800 : loss 3.7832589149475098 acc 0\n",
      " 2900 : loss 4.650742530822754 acc 0\n",
      " 3000 : loss 3.811920166015625 acc 0\n",
      " 3100 : loss 5.260229587554932 acc 0\n",
      " 3200 : loss 4.585493564605713 acc 0\n",
      " 3300 : loss 3.5618958473205566 acc 0\n",
      " 3400 : loss 4.9025373458862305 acc 0\n",
      " 3500 : loss 4.474512100219727 acc 0\n",
      " 3600 : loss 5.230148792266846 acc 0\n",
      " 3700 : loss 4.35326623916626 acc 0\n",
      " 3800 : loss 2.3996734619140625 acc 0\n",
      " 3900 : loss 3.531862735748291 acc 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (16, 0) for Tensor 'inputs_xdata:0', which has shape '(?, 5)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e1c2edb8d594>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#         print(feed_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#         lo, acc, opt = Ses.run([loss, accuracy, optimizer], feed_dict=feed_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mlo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;31m#         accuracy_train+=acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlo\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdelta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_train\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    973\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    976\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (16, 0) for Tensor 'inputs_xdata:0', which has shape '(?, 5)'"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "delta = 0.5\n",
    "\n",
    "Ses = tf.Session()\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=Ses, coord=coord)\n",
    "Ses.run(tf.global_variables_initializer())\n",
    "\n",
    "print('start learning!')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    print('{} start'.format(epoch))\n",
    "    \n",
    "    loss_train = 0\n",
    "    loss_test = 0\n",
    "    accuracy_train = 0\n",
    "    accuracy_test =0\n",
    "    \n",
    "    \n",
    "#     for i in range(1000):\n",
    "    i=0\n",
    "#     try:\n",
    "    while True:\n",
    "        seq_, x_in, y_in = Ses.run([batch_seq, batch_x, batch_y])\n",
    "        feed_data = {X:x_in, Y:y_in, seq_len:seq_}\n",
    "#         print(feed_data)\n",
    "#         lo, acc, opt = Ses.run([loss, accuracy, optimizer], feed_dict=feed_data)\n",
    "        lo, opt = Ses.run([loss, optimizer], feed_dict=feed_data)\n",
    "#         accuracy_train+=acc\n",
    "        loss_train = lo * delta + loss_train * (1-delta)\n",
    "        i+=1\n",
    "        if i%100 ==0:\n",
    "            print(' {} : loss {} acc {}'.format(i, lo, accuracy_train))\n",
    "#     except:\n",
    "#         print('batch : ',i)\n",
    "#         accuracy_train /= \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"batch:0\", shape=(16,), dtype=int64)\n",
      "[] []\n",
      "dd\n"
     ]
    }
   ],
   "source": [
    "# feed_data = {X:}\n",
    "# opt = Ses.run([outputs], feed_dict=feed_data)\n",
    "# print(opt[0])\n",
    "# feed_data\n",
    "print(batch_seq)\n",
    "seq_, x_in, y_in = Ses.run([batch_seq, batch_x, batch_y])\n",
    "print(x_in, y_in)\n",
    "if len(x_in) != 0:\n",
    "    print('dd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = tf.nn.top_k(outputs,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1e3c0eb5b8e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mseq_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mseq_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_in\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mfeed_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "seq_, x_in, y_in = Ses.run([batch_seq, batch_x, batch_y])\n",
    "feed_data = {X:x_in, seq_len:seq_, Y:y_in}\n",
    "pr = Ses.run(predict, feed_dict=feed_data)\n",
    "feed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob = pr[0]\n",
    "probidx = pr[1]\n",
    "idx_to_word = []\n",
    "with open(vocabulary, 'r', newline='', encoding='utf-8') as vocab:\n",
    "    words = csv.reader(vocab)\n",
    "    for word in words:\n",
    "        idx_to_word.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6282    4    8    2    9]\n",
      " [5482    7   15    5   37]\n",
      " [   5  186    3    3    1]\n",
      " [  23    3 1216    6  943]\n",
      " [   4    4    6   31    4]\n",
      " [   2   16    3 5482   25]\n",
      " [  31    4    8    2    9]\n",
      " [  15    5   37    5   41]\n",
      " [   3    3    1   23    3]\n",
      " [ 482    6 1216    6  413]\n",
      " [   4    4    6   15    5]\n",
      " [  72    4    2   18    2]\n",
      " [  10   10   15    5   80]\n",
      " [   5   84    5  144    3]\n",
      " [   4    2  294    7    3]\n",
      " [   1   23    3 1216    6]] [[   4    8    2    9 5482]\n",
      " [   7   15    5   37    5]\n",
      " [ 186    3    3    1   23]\n",
      " [   3 1216    6  943    4]\n",
      " [   4    6   31    4    2]\n",
      " [  16    3 5482   25   31]\n",
      " [   4    8    2    9   15]\n",
      " [   5   37    5   41    3]\n",
      " [   3    1   23    3  482]\n",
      " [   6 1216    6  413    4]\n",
      " [   4    6   15    5   72]\n",
      " [   4    2   18    2   10]\n",
      " [  10   15    5   80    5]\n",
      " [  84    5  144    3    4]\n",
      " [   2  294    7    3    1]\n",
      " [  23    3 1216    6  482]]\n",
      "['from'] 9\n",
      "['if'] 3\n",
      "['self'] 1\n",
      "['0'] 5\n",
      "['if'] 3\n",
      "\n",
      "['if'] 3\n",
      "['if'] 3\n",
      "['0'] 5\n",
      "['if'] 3\n",
      "['if'] 3\n",
      "\n",
      "['self'] 1\n",
      "['return'] 4\n",
      "['self'] 1\n",
      "['0'] 5\n",
      "['if'] 3\n",
      "\n",
      "['return'] 4\n",
      "['def'] 2\n",
      "['self'] 1\n",
      "['return'] 4\n",
      "['return'] 4\n",
      "\n",
      "['from'] 9\n",
      "['def'] 2\n",
      "['def'] 2\n",
      "['from'] 9\n",
      "['144'] 18\n",
      "\n",
      "['def'] 2\n",
      "['self'] 1\n",
      "['0'] 5\n",
      "['if'] 3\n",
      "['0'] 5\n",
      "\n",
      "['if'] 3\n",
      "['0'] 5\n",
      "['if'] 3\n",
      "['if'] 3\n",
      "['self'] 1\n",
      "\n",
      "['return'] 4\n",
      "['self'] 1\n",
      "['0'] 5\n",
      "['if'] 3\n",
      "['return'] 4\n",
      "\n",
      "['def'] 2\n",
      "['self'] 1\n",
      "['return'] 4\n",
      "['return'] 4\n",
      "['in'] 10\n",
      "\n",
      "['in'] 10\n",
      "['if'] 3\n",
      "['def'] 2\n",
      "['from'] 9\n",
      "['144'] 18\n",
      "\n",
      "['0'] 5\n",
      "['if'] 3\n",
      "['0'] 5\n",
      "['if'] 3\n",
      "['if'] 3\n",
      "\n",
      "['self'] 1\n",
      "['self'] 1\n",
      "['return'] 4\n",
      "['if'] 3\n",
      "['self'] 1\n",
      "\n",
      "['if'] 3\n",
      "['self'] 1\n",
      "['return'] 4\n",
      "['self'] 1\n",
      "['return'] 4\n",
      "\n",
      "['def'] 2\n",
      "['def'] 2\n",
      "['self'] 1\n",
      "['0'] 5\n",
      "['if'] 3\n",
      "\n",
      "['def'] 2\n",
      "['def'] 2\n",
      "['in'] 10\n",
      "['self'] 1\n",
      "['from'] 9\n",
      "\n",
      "['in'] 10\n",
      "['if'] 3\n",
      "['self'] 1\n",
      "['return'] 4\n",
      "['if'] 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probidx\n",
    "print(feed_data[X], feed_data[Y])\n",
    "for line in probidx:\n",
    "    for idx in line:\n",
    "#         for each_idx in idx:\n",
    "        print(idx_to_word[idx[0]], idx[0])\n",
    "    print()\n",
    "# predic_word = [idx_to_word[i] for i in probidx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
