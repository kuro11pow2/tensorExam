{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import rnn_cell_impl as core_rnn_cell_impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "input_size = 1\n",
    "max_len = 10\n",
    "rnn_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<tf.Tensor 'EncoderInput0:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'EncoderInput1:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'EncoderInput2:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'EncoderInput3:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'EncoderInput4:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'EncoderInput5:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'EncoderInput6:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'EncoderInput7:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'EncoderInput8:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'EncoderInput9:0' shape=(32, 1) dtype=float32>],\n",
       " [<tf.Tensor 'DecoderInput0:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'DecoderInput1:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'DecoderInput2:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'DecoderInput3:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'DecoderInput4:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'DecoderInput5:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'DecoderInput6:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'DecoderInput7:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'DecoderInput8:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'DecoderInput9:0' shape=(32, 1) dtype=float32>,\n",
       "  <tf.Tensor 'DecoderInput10:0' shape=(32, 1) dtype=float32>])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = tf.contrib.rnn.GRUCell(rnn_size)\n",
    "encoder_inputs= []    \n",
    "decoder_inputs = []\n",
    "for i in range(max_len):\n",
    "    encoder_inputs.append(tf.placeholder(\n",
    "        tf.float32, [batch_size, input_size], name=\"EncoderInput%d\" % i))\n",
    "for i in range(max_len + 1):\n",
    "    decoder_inputs.append(tf.placeholder(\n",
    "        tf.float32, [batch_size, input_size], name=\"DecoderInput%d\" % i))\n",
    "encoder_inputs, decoder_inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'rnn/rnn/gru_cell/add:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_1:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_2:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_3:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_4:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_5:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_6:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_7:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_8:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_9:0' shape=(32, 32) dtype=float32>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder_inputs_once = tf.placeholder(tf.float32,[32,1,10])\n",
    "encoder_outputs, final_state = tf.contrib.rnn.static_rnn(cell,encoder_inputs, dtype=tf.float32)\n",
    "# encoder_outputs, final_state = tf.nn.dynamic_rnn(cell,encoder_inputs_once, dtype=tf.float32)\n",
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'zeros:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_1:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_2:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_3:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_4:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_5:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_6:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_7:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_8:0' shape=(32, 32) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/gru_cell/add_9:0' shape=(32, 32) dtype=float32>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(encoder_outputs)\n",
    "# print(np.asarray([tf.zeros([32,32])]).shape)\n",
    "encoder_outputs = [tf.zeros([batch_size, 32])] + encoder_outputs\n",
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat:0\", shape=(32, 11, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "top_states = [tf.reshape(e, [-1, 1, cell.output_size]) for e in encoder_outputs]\n",
    "attention_states = tf.concat(axis=1, values=top_states)\n",
    "print(attention_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder를 만든다. (batch_size , sequence , input dim) 더미 아웃풋을 위해 시퀀스를 +1해준다\n",
    "\n",
    "(원래는 10개)\n",
    "\n",
    "pointer decoder에 해당하는 값을 decoder_inputs값과 함께 넣어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size Tensor(\"point_decoder_2/strided_slice:0\", shape=(), dtype=int32) attn_size 32\n",
      "Tensor(\"point_decoder_2/zeros:0\", shape=(?, 32), dtype=float32)\n",
      "decoder_inputs length 11\n",
      "inp Tensor(\"DecoderInput0:0\", shape=(32, 1), dtype=float32)\n",
      "attns Tensor(\"point_decoder_2/zeros:0\", shape=(?, 32), dtype=float32)\n",
      "states[-1] Tensor(\"rnn/rnn/gru_cell/add_9:0\", shape=(32, 32), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Trying to share variable rnn/gru_cell/gates/kernel, but specified shape (64, 64) and found shape (33, 64).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-845ec3244fa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m \u001b[0mpointer_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-845ec3244fa3>\u001b[0m in \u001b[0;36mpointer_decoder\u001b[1;34m(decoder_inputs, final_state, attention_states, cell, feed_prev, dtype)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'states[-1] {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;31m# Run the RNN.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mcell_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0mstates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;31m# Run the attention mechanism.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda_python\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope)\u001b[0m\n\u001b[0;32m    178\u001b[0m       with vs.variable_scope(vs.get_variable_scope(),\n\u001b[0;32m    179\u001b[0m                              custom_getter=self._rnn_get_variable):\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda_python\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;31m# Apply activity regularization.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda_python\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, state)\u001b[0m\n\u001b[0;32m    293\u001b[0m       value = math_ops.sigmoid(\n\u001b[0;32m    294\u001b[0m           _linear([inputs, state], 2 * self._num_units, True, bias_ones,\n\u001b[1;32m--> 295\u001b[1;33m                   self._kernel_initializer))\n\u001b[0m\u001b[0;32m    296\u001b[0m       \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_or_size_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"candidate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda_python\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m_linear\u001b[1;34m(args, output_size, bias, bias_initializer, kernel_initializer)\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[0m_WEIGHTS_VARIABLE_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtotal_arg_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m         initializer=kernel_initializer)\n\u001b[0m\u001b[0;32m   1018\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m       \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda_python\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m   1063\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[0;32m   1066\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1067\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32mD:\\anaconda_python\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m    960\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mD:\\anaconda_python\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m    358\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[0;32m    361\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m       return _true_getter(\n",
      "\u001b[1;32mD:\\anaconda_python\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m_rnn_get_variable\u001b[1;34m(self, getter, *args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[0mvariable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     trainable = (variable in tf_variables.trainable_variables() or\n\u001b[0;32m    185\u001b[0m                  (isinstance(variable, tf_variables.PartitionedVariable) and\n",
      "\u001b[1;32mD:\\anaconda_python\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[0;32m    350\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m           use_resource=use_resource)\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda_python\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[0;32m    667\u001b[0m         raise ValueError(\"Trying to share variable %s, but specified shape %s\"\n\u001b[0;32m    668\u001b[0m                          \" and found shape %s.\" % (name, shape,\n\u001b[1;32m--> 669\u001b[1;33m                                                    found_var.get_shape()))\n\u001b[0m\u001b[0;32m    670\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mdtype_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Trying to share variable rnn/gru_cell/gates/kernel, but specified shape (64, 64) and found shape (33, 64)."
     ]
    }
   ],
   "source": [
    "def pointer_decoder(decoder_inputs, final_state, attention_states, cell, feed_prev=True, dtype=tf.float32):\n",
    "    with tf.variable_scope(\"point_decoder\", reuse=True):\n",
    "        batch_size = tf.shape(decoder_inputs[0])[0]  #배치 사이즈\n",
    "        input_size_ = decoder_inputs[0].get_shape()[1].value # input size 1\n",
    "        attn_length = attention_states.get_shape()[1].value # sequence 11,\n",
    "        attn_size = attention_states.get_shape()[2].value #input_dim 32\n",
    "        attention_vec_size = attn_size  # Size of query vectors for attention. 32 \n",
    "\n",
    "        hidden = tf.reshape(attention_states, [-1, attn_length, 1, attn_size])\n",
    "        \n",
    "        k = tf.get_variable(name=\"AttnW\", shape =[1, 1, attn_size, attention_vec_size])\n",
    "        hidden_features = nn_ops.conv2d(hidden, k, [1, 1, 1, 1], \"SAME\")  # 32 11 1 32\n",
    "        v = tf.get_variable(name=\"AttnV\", shape=[attention_vec_size])\n",
    "        states = [final_state]   # [32 32]\n",
    "        \n",
    "        outputs = []\n",
    "        prev = None\n",
    "        batch_attn_size = tf.stack([batch_size, attn_size])    # tf.stack([32, 32])  = 64\n",
    "        attns = tf.zeros(batch_attn_size, dtype=dtype)\n",
    "        \n",
    "        print('batch_size',batch_size, 'attn_size',attn_size)\n",
    "        attns.set_shape([None, attn_size])\n",
    "        print(attns)\n",
    "        inps = []\n",
    "        \n",
    "        def attention(query):\n",
    "            \"\"\"Point on hidden using hidden_features and query.\"\"\"\n",
    "            with tf.variable_scope(\"Attention\"):\n",
    "                y = core_rnn_cell_impl._linear(query, attention_vec_size, True)\n",
    "                y = array_ops.reshape(y, [-1, 1, 1, attention_vec_size])\n",
    "                # Attention mask is a softmax of v^T * tanh(...).\n",
    "                s = math_ops.reduce_sum(\n",
    "                    v * math_ops.tanh(hidden_features + y), [2, 3])\n",
    "                return s\n",
    "            \n",
    "        print('decoder_inputs length' , len(decoder_inputs))\n",
    "        for i in range(len(decoder_inputs)):\n",
    "            if i > 0:\n",
    "#                 tf.get_variable_scope().reuse_variables()\n",
    "                print(tf.get_variable_scope())\n",
    "            inp = decoder_inputs[i]\n",
    "\n",
    "            if feed_prev and i > 0:\n",
    "                inp = tf.stack(decoder_inputs)\n",
    "                inp = tf.transpose(inp, perm=[1, 0, 2])\n",
    "                inp = tf.reshape(inp, [-1, attn_length, input_size_])\n",
    "                inp = tf.reduce_sum(inp * tf.reshape(tf.nn.softmax(output), [-1, attn_length, 1]), 1)\n",
    "                inp = tf.stop_gradient(inp)\n",
    "                inps.append(inp)\n",
    "\n",
    "            # Use the same inputs in inference, order internaly\n",
    "\n",
    "            # Merge input and previous attentions into one vector of the right size.\n",
    "            x = core_rnn_cell_impl._linear([inp, attns], output_size=cell.output_size, bias=True)\n",
    "            print('inp {}'.format(inp))\n",
    "            print('attns {}'.format(attns))\n",
    "            print('states[-1] {}'.format(states[-1]))\n",
    "            # Run the RNN.\n",
    "            cell_output, new_state = cell(x, states[-1])\n",
    "            states.append(new_state)\n",
    "            # Run the attention mechanism.\n",
    "            output = attention(new_state)\n",
    "\n",
    "            outputs.append(output)\n",
    "    return outputs, states, inps\n",
    "    \n",
    "pointer_decoder(decoder_inputs, final_state, attention_states, cell)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
