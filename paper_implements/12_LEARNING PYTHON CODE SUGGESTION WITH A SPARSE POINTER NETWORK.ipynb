{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### statically-typed language : java,C, C++\n",
    " 컴파일시에 에러가 검출된다. 타입구분이 명확한것들을 정적타입 랭귀지 라함.\n",
    " \n",
    "### dynamic-typed language : python, javascript, Ruby... \n",
    " 인터프리터 언어라고도한다. 타입에 딱히 신경쓰지않아도 개발이가능하며 개발속도 기본적으로 빠르다.\n",
    " \n",
    "IDE에서 statical language 는 코드 suggestion이 잘 적용되지만, python같은 dynamic language 는 지원이 상대적으로 부족하다.\n",
    "\n",
    "특히나 modern IDE에서는 관용구나 표현식을 제공하지않는다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import datetime\n",
    "from glob import iglob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path='data_samples/mapping.map'\n",
    "data_pattern = 'all_{-type-}_data.dat'\n",
    "hidden_size = 10\n",
    "seq_length = 10\n",
    "batch_size = 10\n",
    "num_samples = 0 # 원래는 100개\n",
    "with open(data_path, \"rb\") as f:\n",
    "        word_to_id = pickle.load(f)\n",
    "vocab_size = len(word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all_train_data.dat.part*'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pattern = data_pattern.replace(\"{-type-}\", \"train\") + \".part*\"\n",
    "data_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_files = [\n",
    "    'D:\\Atlassian\\git\\tensorflowexam\\paper_implements\\data_samples\\affinelayer\\pix2pix-tensorflow\\tools\\download-dataset.py',\n",
    "'D:\\Atlassian\\git\\tensorflowexam\\paper_implements\\data_samples\\affinelayer\\pix2pix-tensorflow\\tools\\process.py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.BasicLSTMCell(\n",
    "    hidden_size, forget_bias=1.0, state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=0.8)\n",
    "actual_lengths = tf.placeholder(tf.int32, [batch_size], name=\"actual_lengths\")\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "targets = tf.placeholder(tf.int32, [seq_length, batch_size], name=\"targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = tf.placeholder(tf.int32, [seq_length, batch_size], name=\"inputs\")\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    _embedding = embedding = tf.get_variable(\"embedding\", [vocab_size, hidden_size],\n",
    "                                                  trainable=True)\n",
    "\n",
    "    inputs = tf.gather(embedding, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'embedding:0' shape=(1458, 10) dtype=float32_ref>,\n",
       " <tf.Tensor 'inputs:0' shape=(10, 10) dtype=int32>,\n",
       " <tf.Tensor 'Gather:0' shape=(10, 10, 10) dtype=float32>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding, input_data, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d9240f64ff3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0m_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_final_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_and_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-d9240f64ff3e>\u001b[0m in \u001b[0;36moutput_and_loss\u001b[1;34m(cell, inputs)\u001b[0m\n\u001b[0;32m     20\u001b[0m             vocab_size)\n\u001b[0;32m     21\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_logits' is not defined"
     ]
    }
   ],
   "source": [
    "def output_and_loss(cell, inputs):\n",
    "    output, state = tf.nn.dynamic_rnn(\n",
    "        cell, inputs, sequence_length=actual_lengths,\n",
    "        initial_state=initial_state)\n",
    "\n",
    "    output = tf.reshape(output, [-1, hidden_size])\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [hidden_size, vocab_size])\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "    logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "    predict = tf.nn.softmax(logits)\n",
    "\n",
    "    labels = tf.reshape(targets, [batch_size * seq_length, 1])\n",
    "\n",
    "    if num_samples > 0:\n",
    "        loss = tf.nn.sampled_softmax_loss(\n",
    "            tf.transpose(softmax_w),\n",
    "            softmax_b, output, \n",
    "            labels, \n",
    "            num_samples, \n",
    "            vocab_size)\n",
    "    else:\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(_logits, tf.reshape(targets, [-1]))\n",
    "\n",
    "    return logits, predict, loss, state\n",
    "_logits, _predict, _loss, _final_state=output_and_loss(cell,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
