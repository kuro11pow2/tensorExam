{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import datetime\n",
    "from glob import iglob\n",
    "import time\n",
    "# import attention\n",
    "from collections import deque\n",
    "import pickle\n",
    "import pyreader\n",
    "import numpy as np\n",
    "import csv\n",
    "from batchmake import Batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481\n"
     ]
    }
   ],
   "source": [
    "datas= 'data_samples/'\n",
    "word_to_id='data_samples/mapping.map'\n",
    "with open(word_to_id, 'rb') as f:\n",
    "    word_to_id = pickle.load(f)\n",
    "inv_map = {v:k for k, v in word_to_id.items() }\n",
    "# batch_data = datas+'output.txt.part0'\n",
    "batch_data = datas+'preprocess.part0'\n",
    "with open(batch_data, 'rb') as f:\n",
    "    picked_data = pickle.load(f)\n",
    "    \n",
    "print(len(picked_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention(inputs, attention_size):\n",
    "    inputs_shape = inputs.shape\n",
    "    sequence_length = inputs_shape[1].value\n",
    "    hidden_size = inputs_shape[2].value\n",
    "    \n",
    "    w_omega = tf.Variable(tf.random_normal([hidden_size,attention_size], stddev=0.1))\n",
    "    b_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n",
    "    u_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n",
    "    \n",
    "    # batch *k , attention_size\n",
    "    v = tf.tanh(tf.matmul(tf.reshape(inputs, [-1,hidden_size]), w_omega)+\n",
    "               tf.reshape(b_omega,[1,-1]))\n",
    "    \n",
    "    vu = tf.matmul(v, tf.reshape(u_omega,[-1,1])) # batch*k,1\n",
    "    exps = tf.reshape(tf.exp(vu), [-1, sequence_length])  # (batch, k)\n",
    "    alphas = exps / tf.reshape(tf.reduce_sum(exps,1), [-1,1])\n",
    "    #(batch,k)\n",
    "    output = tf.reduce_sum(inputs * tf.reshape(alphas, [-1, sequence_length,1]),1)\n",
    "    # batch * sequence * hidden -> batch * hidden\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size=32\n",
    "sequence=5\n",
    "input_dim=1\n",
    "attention_size = 50\n",
    "batch_size=16\n",
    "grucell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size)\n",
    "X = tf.placeholder(tf.float32, [None, sequence,input_dim])\n",
    "Y = tf.placeholder(tf.float32, [None, sequence, input_dim])\n",
    "with tf.variable_scope('RNN'):\n",
    "    outputs, states = tf.nn.dynamic_rnn(grucell,X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attention_output = attention(outputs, attention_size=attention_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sum_1:0\", shape=(?, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(attention_output)\n",
    "\n",
    "keep_prob = 0.5\n",
    "drop = tf.nn.dropout(attention_output, keep_prob=keep_prob)\n",
    "\n",
    "w = tf.Variable(tf.truncated_normal([hidden_size,1], stddev=0.1))\n",
    "b = tf.Variable(tf.constant(0., shape=[1]))\n",
    "y_hat = tf.nn.xw_plus_b(drop,w,b)\n",
    "y_hat = tf.squeeze(y_hat)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_hat, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data partition data_samples/preprocess.part0 with 481 examples\n",
      "[<pyreader.Container object at 0x000001C9A750A518>, <pyreader.Container object at 0x000001C9A78A1898>, <pyreader.Container object at 0x000001C9A79122B0>, <pyreader.Container object at 0x000001C9A79D2BA8>, <pyreader.Container object at 0x000001C9A7953358>, <pyreader.Container object at 0x000001C9A79803C8>, <pyreader.Container object at 0x000001C9A79EADD8>, <pyreader.Container object at 0x000001C9A7A06978>, <pyreader.Container object at 0x000001C9A7A12278>, <pyreader.Container object at 0x000001C9A7A12390>, <pyreader.Container object at 0x000001C9A7A124A8>, <pyreader.Container object at 0x000001C9A7A125C0>, <pyreader.Container object at 0x000001C9A7A126D8>, <pyreader.Container object at 0x000001C9A7A127F0>, <pyreader.Container object at 0x000001C9A7A12908>, <pyreader.Container object at 0x000001C9A7A12A20>]\n",
      "(5, 16) (5, 16) (5, 16, 1) (16, 5) (16,)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (5, 16) for Tensor 'Placeholder:0', which has shape '(?, 5, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-337409c12409>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#inputs :  batch, sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mlo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    973\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    976\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (5, 16) for Tensor 'Placeholder:0', which has shape '(?, 5, 1)'"
     ]
    }
   ],
   "source": [
    "batcher = Batcher([batch_data], batch_size=batch_size, seq_length=sequence) #batchsize, sequence\n",
    "\n",
    "for batch in batcher:\n",
    "    for i, feed_data  in enumerate(batcher.sequence_iterator(batch)):\n",
    "        inputs,targets,masks,identifiers,actual_lengths = feed_data\n",
    "        print(inputs.shape , targets.shape, masks.shape, identifiers.shape,actual_lengths.shape)\n",
    "        print(actual_lengths)\n",
    "        \n",
    "        feed_data = {X:inputs, Y:targets}\n",
    "        #inputs :  batch, sequence\n",
    "        \n",
    "        lo, opt = s.run([loss,optimizer], feed_dict=feed_data)\n",
    "        \n",
    "            \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
