{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import datetime\n",
    "from glob import iglob\n",
    "import time\n",
    "# import attention\n",
    "from collections import deque\n",
    "import pickle\n",
    "import pyreader\n",
    "import numpy as np\n",
    "import csv\n",
    "from batchmake import Batcher\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22669\n"
     ]
    }
   ],
   "source": [
    "datas= 'data_samples/'\n",
    "vocabulary = 'vocab.csv'\n",
    "vocabs = []\n",
    "with open(vocabulary, 'r', newline='', encoding='utf-8') as vocab:\n",
    "    words = csv.reader(vocab)\n",
    "    for word in words:\n",
    "        vocabs.append(word)\n",
    "# word_to_id='data_samples/mapping.map'\n",
    "# with open(word_to_id, 'rb') as f:\n",
    "#     word_to_id = pickle.load(f)\n",
    "# inv_map = {v:k for k, v in word_to_id.items() }\n",
    "# batch_data = datas+'output.txt.part0'\n",
    "batch_data = datas+'preprocess.part0'\n",
    "with open(batch_data, 'rb') as f:\n",
    "    picked_data = pickle.load(f)\n",
    "print(len(vocabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention(inputs, attention_size):\n",
    "    inputs_shape = inputs.shape\n",
    "    sequence_length = inputs_shape[1].value\n",
    "    hidden_size = inputs_shape[2].value\n",
    "    \n",
    "    w_omega = tf.Variable(tf.random_normal([hidden_size,attention_size], stddev=0.1))\n",
    "    b_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n",
    "    u_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n",
    "    \n",
    "    # batch *k , attention_size\n",
    "    v = tf.tanh(tf.matmul(tf.reshape(inputs, [-1,hidden_size]), w_omega)+\n",
    "               tf.reshape(b_omega,[1,-1]))\n",
    "    \n",
    "    vu = tf.matmul(v, tf.reshape(u_omega,[-1,1])) # batch*k,1\n",
    "    exps = tf.reshape(tf.exp(vu), [-1, sequence_length])  # (batch, k)\n",
    "    alphas = exps / tf.reshape(tf.reduce_sum(exps,1), [-1,1])\n",
    "    #(batch,k)\n",
    "    output = tf.reduce_sum(inputs * tf.reshape(alphas, [-1, sequence_length,1]),1)\n",
    "    # batch * sequence * hidden -> batch * hidden\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=32\n",
    "sequence=5\n",
    "embedding_dim=100\n",
    "attention_size = 50\n",
    "batch_size=1\n",
    "vocab_size=len(vocabs)\n",
    "grucell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size)\n",
    "X = tf.placeholder(tf.int32, [None, sequence], name='inputs_xdata')\n",
    "Y = tf.placeholder(tf.float32, [None, sequence], name='targets_ydata')\n",
    "seq_len = tf.placeholder(tf.int32, [None], name='seq_len')\n",
    "\n",
    "embedding_variable = tf.Variable(tf.random_uniform([vocab_size, embedding_dim],-1.0,1.0), trainable=True)\n",
    "batch_embedded = tf.nn.embedding_lookup(embedding_variable, X)\n",
    "\n",
    "\n",
    "with tf.variable_scope('RNN'):\n",
    "    outputs, states = tf.nn.dynamic_rnn(grucell,\n",
    "                                        inputs=batch_embedded,\n",
    "                                        sequence_length=seq_len,\n",
    "                                        dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_output = attention(outputs, attention_size=attention_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = 0.5\n",
    "drop = tf.nn.dropout(attention_output, keep_prob=keep_prob)\n",
    "w = tf.Variable(tf.truncated_normal([hidden_size,1], stddev=0.1))\n",
    "b = tf.Variable(tf.constant(0., shape=[1]))\n",
    "y_hat = tf.nn.xw_plus_b(drop,w,b)\n",
    "\n",
    "y_hat = tf.squeeze(y_hat)\n",
    "\n",
    "loss = -tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_hat, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5aa691408485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#     print(feed_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#     try:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mlo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;31m#     print(feed_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#     except:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_name_queue = tf.train.string_input_producer(['inputs'])\n",
    "reader = tf.TFRecordReader()\n",
    "_, single_x = reader.read(file_name_queue)\n",
    "\n",
    "context_features = {\n",
    "    \"length\": tf.FixedLenFeature([], dtype=tf.int64)\n",
    "}\n",
    "sequence_features = {\n",
    "    \"tokens\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "    \"labels\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "\n",
    "context_parsed, sequence_parsed = tf.parse_single_sequence_example(serialized=single_x,\n",
    "                                 context_features=context_features,\n",
    "                                 sequence_features=sequence_features\n",
    "                                )\n",
    "# batch_seq, batch_x, batch_y = tf.train.shuffle_batch(tensors=[context_parsed['length'],sequence_parsed['tokens'],sequence_parsed['labels']],\n",
    "#                                                      batch_size=batch_size, \n",
    "#                                                      capacity=5000,\n",
    "#                                                      num_threads=1,\n",
    "#                                                      min_after_dequeue=1000,\n",
    "#                                                     )\n",
    "batch_seq, batch_x, batch_y = tf.train.batch(tensors=[context_parsed['length'],sequence_parsed['tokens'],sequence_parsed['labels']],\n",
    "                                                     batch_size=batch_size, \n",
    "                                                     capacity=5000,\n",
    "                                                     num_threads=1,\n",
    "                                             dynamic_pad=True\n",
    "                                                    )\n",
    "\n",
    "\n",
    "Ses = tf.Session()\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=Ses, coord=coord)\n",
    "Ses.run(tf.global_variables_initializer())\n",
    "\n",
    "# print(tokens_['tokens'])\n",
    "for i in range(1000):\n",
    "    seq_, x_in, y_in = Ses.run([batch_seq, batch_x, batch_y])\n",
    "    feed_data = {X:x_in, Y:y_in, seq_len:seq_}\n",
    "#     print(feed_data)\n",
    "#     try:\n",
    "    lo, opt = Ses.run([loss,optimizer], feed_dict=feed_data)\n",
    "#     print(feed_data)\n",
    "#     except:\n",
    "#         print('error occured!!!  ',i, feed_data)\n",
    "#         break\n",
    "#     print('loss',lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"transpose_1:0\", shape=(1, 5, 11), dtype=int32) Tensor(\"Slice_1:0\", shape=(1, 5, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "filename_queue = tf.train.string_input_producer(['./inputs.csv'])\n",
    "reader = tf.TextLineReader()\n",
    "key, record_string = reader.read_up_to(filename_queue,num_records=sequence)\n",
    "# key, record_string = reader.read(filename_queue)\n",
    "seq_lengths = [[11]]\n",
    "# record_string = tf.reshape(record_string, [-1])\n",
    "record_defaults = [[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1]]\n",
    "batc_record = tf.cast(tf.decode_csv(record_string, record_defaults=record_defaults),tf.int32)\n",
    "batc_record = tf.reshape(batc_record,[input_dim,sequence])\n",
    "# target_string = tf.slice(record_string, [1,0],[1,-1])\n",
    "# file_content = tf.read_file(filename_queue)\n",
    "# batc_record = tf.transpose(batc_record,[0,2,1])\n",
    "# output = tf.train.batch([batc_record], batch_size=batch_size, dynamic_pad=True,allow_smaller_final_batch=False)\n",
    "output = tf.train.shuffle_batch(tensors=[batc_record],\n",
    "                                batch_size=batch_size,\n",
    "                                capacity = 5000,\n",
    "                                num_threads=1,\n",
    "                                min_after_dequeue=1000\n",
    "                               )\n",
    "output = tf.transpose(output,[0,2,1])\n",
    "target = tf.slice(output, [0,0,1],[-1,-1,-1])\n",
    "print(output,target)\n",
    "# output = tf.reshape(output,[2,3,11])\n",
    "Ses = tf.Session()\n",
    "\n",
    "# sequences, output = tf.contrib.training.bucket_by_sequence_length(input_length=seq_lengths,\n",
    "#                                              tensors=[batc_record],\n",
    "#                                              batch_size=1,\n",
    "#                                              bucket_boundaries=[11,13],\n",
    "#                                              dynamic_pad=True\n",
    "#                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Input to reshape is a tensor with 11 values, but the requested shape has 55\n",
      "\t [[Node: Reshape_6 = Reshape[T=DT_INT32, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Cast/x, Reshape_6/shape)]]\n",
      "loss -36.6007\n",
      "loss 41.6747\n",
      "loss 23.0561\n",
      "loss -17.2172\n",
      "loss 101.85\n",
      "loss 65.1391\n",
      "loss 12.8645\n",
      "loss -30.7384\n",
      "loss 86.8514\n",
      "loss 31.4633\n",
      "loss -3.43664\n",
      "loss -3.66925\n",
      "loss 53.6685\n",
      "loss -1.15071\n",
      "loss -7.68049\n",
      "loss 65.4639\n",
      "loss -6.19446\n",
      "loss -2.29135\n",
      "loss -0.589737\n",
      "loss -38.9972\n",
      "loss 32.6997\n",
      "loss -18.9629\n",
      "loss 2.42858\n",
      "loss -3.93419\n",
      "loss 115.48\n",
      "loss -14.4266\n",
      "loss 19.9054\n",
      "loss -106.323\n",
      "loss -7.46684\n",
      "loss -32.4471\n",
      "loss -73.1171\n",
      "loss -24.6179\n",
      "loss -164.784\n",
      "loss 2.44641\n",
      "loss 41.001\n",
      "loss -33.9733\n",
      "loss -130.663\n",
      "loss 51.621\n",
      "loss -631.38\n",
      "loss -10.008\n",
      "loss -7.0104\n",
      "loss -7.89129\n",
      "loss -39.6123\n",
      "loss -38.734\n",
      "loss 98.0991\n",
      "loss -3.1538\n",
      "loss -71.763\n",
      "loss -198.999\n",
      "loss 1.77701\n",
      "loss -4.88747\n",
      "loss -10.3605\n",
      "loss 2.18155\n",
      "loss -66.6167\n",
      "loss -14.6302\n",
      "loss 11.9676\n",
      "loss -10.3805\n",
      "loss -10.5226\n",
      "loss -157.263\n",
      "loss -1.76901\n",
      "loss -37.6872\n",
      "loss -10.3144\n",
      "loss -185.016\n",
      "loss -22.7472\n",
      "loss -10.7781\n",
      "loss 2.0804\n",
      "loss 33.541\n",
      "loss -19.6353\n",
      "loss 5.40044\n",
      "loss -6.74132\n",
      "loss -27.8683\n",
      "loss -38.9265\n",
      "loss -595.36\n",
      "loss -17.6783\n",
      "loss -4.38216\n",
      "loss -2.6463\n",
      "loss 0.494295\n",
      "loss -35.335\n",
      "loss -9.39719\n",
      "loss -219.013\n",
      "loss -16.9919\n",
      "loss -185.606\n",
      "loss -14.1428\n",
      "loss -278.766\n",
      "loss -20.558\n",
      "loss -8.4929\n",
      "loss -340.312\n",
      "loss 15.1794\n",
      "loss 124.773\n",
      "loss 110.134\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "RandomShuffleQueue '_7_shuffle_batch_1/random_shuffle_queue' is closed and has insufficient elements (requested 1, current size 0)\n\t [[Node: shuffle_batch_1 = QueueDequeueManyV2[component_types=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch_1/random_shuffle_queue, shuffle_batch_1/n)]]\n\nCaused by op 'shuffle_batch_1', defined at:\n  File \"D:\\python3_5anaconda\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\python3_5anaconda\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-c72f7e01de03>\", line 18, in <module>\n    min_after_dequeue=1000\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 1217, in shuffle_batch\n    name=name)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 788, in _shuffle_batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 457, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 946, in _queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nOutOfRangeError (see above for traceback): RandomShuffleQueue '_7_shuffle_batch_1/random_shuffle_queue' is closed and has insufficient elements (requested 1, current size 0)\n\t [[Node: shuffle_batch_1 = QueueDequeueManyV2[component_types=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch_1/random_shuffle_queue, shuffle_batch_1/n)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: RandomShuffleQueue '_7_shuffle_batch_1/random_shuffle_queue' is closed and has insufficient elements (requested 1, current size 0)\n\t [[Node: shuffle_batch_1 = QueueDequeueManyV2[component_types=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch_1/random_shuffle_queue, shuffle_batch_1/n)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-eaac7f1a8e1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0moutput_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mfeed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0moutput_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtarget_\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#     try:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: RandomShuffleQueue '_7_shuffle_batch_1/random_shuffle_queue' is closed and has insufficient elements (requested 1, current size 0)\n\t [[Node: shuffle_batch_1 = QueueDequeueManyV2[component_types=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch_1/random_shuffle_queue, shuffle_batch_1/n)]]\n\nCaused by op 'shuffle_batch_1', defined at:\n  File \"D:\\python3_5anaconda\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\python3_5anaconda\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-c72f7e01de03>\", line 18, in <module>\n    min_after_dequeue=1000\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 1217, in shuffle_batch\n    name=name)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 788, in _shuffle_batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 457, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 946, in _queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"D:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nOutOfRangeError (see above for traceback): RandomShuffleQueue '_7_shuffle_batch_1/random_shuffle_queue' is closed and has insufficient elements (requested 1, current size 0)\n\t [[Node: shuffle_batch_1 = QueueDequeueManyV2[component_types=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch_1/random_shuffle_queue, shuffle_batch_1/n)]]\n"
     ]
    }
   ],
   "source": [
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=Ses, coord=coord)\n",
    "Ses.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(1000):\n",
    "    output_,target_ = Ses.run([output,target])\n",
    "    feed_data = {X:output_, Y:target_}\n",
    "#     try:\n",
    "    lo, opt = Ses.run([loss,optimizer], feed_dict=feed_data)\n",
    "#     print(feed_data)\n",
    "#     except:\n",
    "#         print('error occured!!!  ',i, feed_data)\n",
    "#         break\n",
    "    print('loss',lo)\n",
    "# batch_x_ = Ses.run([batch_x])\n",
    "\n",
    "# print(np.array(batch_x_[0]))\n",
    "# print(np.array(batch_x_[0]))\n",
    "# print(batch_x.shape)\n",
    "# output_,target_=Ses.run([output,target])\n",
    "# print(np.array(target_))\n",
    "# print(np.array(target_).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sum_1:0\", shape=(?, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "keep_prob = 0.5\n",
    "drop = tf.nn.dropout(attention_output, keep_prob=keep_prob)\n",
    "\n",
    "w = tf.Variable(tf.truncated_normal([hidden_size,1], stddev=0.1))\n",
    "b = tf.Variable(tf.constant(0., shape=[1]))\n",
    "y_hat = tf.nn.xw_plus_b(drop,w,b)\n",
    "y_hat = tf.squeeze(y_hat)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_hat, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data partition data_samples/preprocess.part0 with 481 examples\n",
      "[<pyreader.Container object at 0x000001C9A750A518>, <pyreader.Container object at 0x000001C9A78A1898>, <pyreader.Container object at 0x000001C9A79122B0>, <pyreader.Container object at 0x000001C9A79D2BA8>, <pyreader.Container object at 0x000001C9A7953358>, <pyreader.Container object at 0x000001C9A79803C8>, <pyreader.Container object at 0x000001C9A79EADD8>, <pyreader.Container object at 0x000001C9A7A06978>, <pyreader.Container object at 0x000001C9A7A12278>, <pyreader.Container object at 0x000001C9A7A12390>, <pyreader.Container object at 0x000001C9A7A124A8>, <pyreader.Container object at 0x000001C9A7A125C0>, <pyreader.Container object at 0x000001C9A7A126D8>, <pyreader.Container object at 0x000001C9A7A127F0>, <pyreader.Container object at 0x000001C9A7A12908>, <pyreader.Container object at 0x000001C9A7A12A20>]\n",
      "(5, 16) (5, 16) (5, 16, 1) (16, 5) (16,)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (5, 16) for Tensor 'Placeholder:0', which has shape '(?, 5, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-337409c12409>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#inputs :  batch, sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mlo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python3_5anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    973\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    976\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (5, 16) for Tensor 'Placeholder:0', which has shape '(?, 5, 1)'"
     ]
    }
   ],
   "source": [
    "batcher = Batcher([batch_data], batch_size=batch_size, seq_length=sequence) #batchsize, sequence\n",
    "\n",
    "for batch in batcher:\n",
    "    for i, feed_data  in enumerate(batcher.sequence_iterator(batch)):\n",
    "        inputs,targets,masks,identifiers,actual_lengths = feed_data\n",
    "        print(inputs.shape , targets.shape, masks.shape, identifiers.shape,actual_lengths.shape)\n",
    "        print(actual_lengths)\n",
    "        \n",
    "        feed_data = {X:inputs, Y:targets}\n",
    "        #inputs :  batch, sequence\n",
    "        \n",
    "        lo, opt = s.run([loss,optimizer], feed_dict=feed_data)\n",
    "        \n",
    "            \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
