{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2-1: Where/How to apply NN?\n",
    "\n",
    "## 레시피 주제 블로그 문서의 서브토픽 자동 태깅\n",
    "레시피 주제의 블로그 문서를 서브토픽에 따라 검색결과를 보여주는 과제를 진행중입니다.\n",
    "예를 들어, 가리비의 서브토픽 가운데,'가리비 손질' 이라는 것이 있다면, 여러 문서들\n",
    "가운데, '가리비 손질'이라는 키워드가 들어간 문서만 보여주는 것입니다. \n",
    "이때, 검색결과의 품질을 높이려면, 키워드 뿐만 아니라, '손질' 이라는 의미에 해당하는\n",
    "문맥정보가 문서에 적절히 들어 있어야 할 것입니다.\n",
    "지식백과에서 '가리비 손질법'을 찾아보면 아래와 같이 나타납니다.\n",
    "> 보관법 : 신선도를 유지하는 것이 가장 중요하며 냉장고에 보관하고 되도록이면 빨리 먹도록 한다.\n",
    "\n",
    "NN을 써서 해보고자하는 것은 임의의 문장/문서가 들어왔을 때, 이것이 해당 서브토픽을 포함하는지\n",
    "여부를 분류하는 것입니다. \n",
    "* 학습셋: 위와 같은 지식백과 추출 문장을 정답으로 간주하 데이터 생성\n",
    "* 모델: 워드임베딩을 포함한 RNN, LSTM (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2-2: Predicting imdb score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: movie_metadata.csv\n",
    "* x_data: numerical features (e.g., num_ciritic_for_reviews, director_face_book_likes, ..., total: 15)\n",
    "* y_data: imdb_score (2 classes)\n",
    "  * 0~9 --> 1 ( > 5) / 0 ( <= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    " * FNN \n",
    "  * \\# of hidden layers: 3, 5\n",
    "  * with drop out / without drop out \n",
    " * hyperparameter\n",
    "   * learning rate: 0.01\n",
    "   * epochs: 10000\n",
    "   \n",
    "## Results\n",
    " * 3 hidden layers + no drop out: 79.4%\n",
    " * 3 hidden layers + drop out: 79.9%\n",
    " * 5 hidden layers + no drop out: 79.1%\n",
    " * 5 hidden layers + drop out: 70.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.decomposition import PCA # Principal Component Analysis module\n",
    "from sklearn.cluster import KMeans # KMeans clustering \n",
    "import matplotlib.pyplot as plt # Python defacto plotting library\n",
    "%matplotlib inline \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Color</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>723.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.78</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>302.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>602.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>994.0</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.35</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Color</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>813.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rob Walker</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   color      director_name  num_critic_for_reviews  duration  \\\n",
       "0  Color      James Cameron                   723.0     178.0   \n",
       "1  Color     Gore Verbinski                   302.0     169.0   \n",
       "2  Color         Sam Mendes                   602.0     148.0   \n",
       "3  Color  Christopher Nolan                   813.0     164.0   \n",
       "4    NaN        Doug Walker                     NaN       NaN   \n",
       "\n",
       "   director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
       "0                      0.0                   855.0  Joel David Moore   \n",
       "1                    563.0                  1000.0     Orlando Bloom   \n",
       "2                      0.0                   161.0      Rory Kinnear   \n",
       "3                  22000.0                 23000.0    Christian Bale   \n",
       "4                    131.0                     NaN        Rob Walker   \n",
       "\n",
       "   actor_1_facebook_likes        gross                           genres  \\\n",
       "0                  1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi   \n",
       "1                 40000.0  309404152.0         Action|Adventure|Fantasy   \n",
       "2                 11000.0  200074175.0        Action|Adventure|Thriller   \n",
       "3                 27000.0  448130642.0                  Action|Thriller   \n",
       "4                   131.0          NaN                      Documentary   \n",
       "\n",
       "          ...          num_user_for_reviews language  country  content_rating  \\\n",
       "0         ...                        3054.0  English      USA           PG-13   \n",
       "1         ...                        1238.0  English      USA           PG-13   \n",
       "2         ...                         994.0  English       UK           PG-13   \n",
       "3         ...                        2701.0  English      USA           PG-13   \n",
       "4         ...                           NaN      NaN      NaN             NaN   \n",
       "\n",
       "        budget  title_year actor_2_facebook_likes imdb_score  aspect_ratio  \\\n",
       "0  237000000.0      2009.0                  936.0        7.9          1.78   \n",
       "1  300000000.0      2007.0                 5000.0        7.1          2.35   \n",
       "2  245000000.0      2015.0                  393.0        6.8          2.35   \n",
       "3  250000000.0      2012.0                23000.0        8.5          2.35   \n",
       "4          NaN         NaN                   12.0        7.1           NaN   \n",
       "\n",
       "  movie_facebook_likes  \n",
       "0                33000  \n",
       "1                    0  \n",
       "2                85000  \n",
       "3               164000  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = pd.read_csv('./movie_metadata.csv') # reads the csv and creates the dataframe called movie\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_list = [] # empty list to contain columns with strings (words)\n",
    "for colname, colvalue in movie.iteritems():\n",
    "    if type(colvalue[1]) == str:\n",
    "         str_list.append(colname)\n",
    "# Get to the numeric columns by inversion            \n",
    "num_list = movie.columns.difference(str_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'actor_1_facebook_likes', u'actor_2_facebook_likes',\n",
       "       u'actor_3_facebook_likes', u'aspect_ratio', u'budget',\n",
       "       u'cast_total_facebook_likes', u'director_facebook_likes', u'duration',\n",
       "       u'facenumber_in_poster', u'gross', u'imdb_score',\n",
       "       u'movie_facebook_likes', u'num_critic_for_reviews',\n",
       "       u'num_user_for_reviews', u'num_voted_users', u'title_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_num = movie[num_list]\n",
    "#del movie # Get rid of movie df as we won't need it now\n",
    "movie_num = movie_num.fillna(value=0, axis=1)\n",
    "movie_num.head()\n",
    "movie_num.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['actor_1_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes', 'aspect_ratio', 'budget', 'cast_total_facebook_likes', 'director_facebook_likes', 'duration', 'facenumber_in_poster', 'gross', 'movie_facebook_likes', 'num_critic_for_reviews', 'num_user_for_reviews', 'num_voted_users', 'title_year'] 15\n",
      "5043\n",
      "(5043, 15)\n",
      "(5043, 1)\n",
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "feature_list = list(movie_num.keys())\n",
    "feature_list.remove('imdb_score')\n",
    "\n",
    "print feature_list, len(feature_list)\n",
    "norm_array = [] \n",
    "for f in feature_list:\n",
    "    norm_array.append(movie_num[f])\n",
    "    \n",
    "X = np.dstack(norm_array)\n",
    "print len(X[0])\n",
    "X = np.reshape(X, (len(X[0]),15))\n",
    "print X.shape\n",
    "\n",
    "# Data Normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_data = X_std = StandardScaler().fit_transform(X)\n",
    "y_data = np.array([ [int(score)] for score in movie_num['imdb_score']])\n",
    "for i, score in enumerate(movie_num['imdb_score']):\n",
    "    if int(score) > 5:\n",
    "        y_data[i][0] = 1\n",
    "    else:\n",
    "        y_data[i][0] = 0\n",
    "print y_data.shape\n",
    "print max(y_data)\n",
    "print min(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5043, 15) (4034, 15) (1009, 15)\n",
      "(5043, 1) (4034, 1) (1009, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "\n",
    "print x_data.shape, x_train.shape, x_test.shape\n",
    "print y_data.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # for reproducibility\n",
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('one_hot', <tf.Tensor 'one_hot:0' shape=(?, 1, 2) dtype=float32>)\n",
      "('reshape', <tf.Tensor 'Reshape:0' shape=(?, 2) dtype=float32>)\n",
      "('X', <tf.Tensor 'Placeholder:0' shape=(?, 15) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 15])\n",
    "\n",
    "nb_classes = 2 # 0, 1\n",
    "#nb_classes = 10 # 0 ~ 9\n",
    "Y = tf.placeholder(tf.int32, [None, 1])  # 0 ~ 1\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)  # one hot\n",
    "print(\"one_hot\", Y_one_hot)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "print(\"reshape\", Y_one_hot)\n",
    "\n",
    "print (\"X\", X)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([15, 9]), name='weight1')\n",
    "#W21 = tf.Variable(tf.random_normal([9, 5]), name='weight21')\n",
    "#W22 = tf.Variable(tf.random_normal([5, 5]), name='weight22')\n",
    "#W2 = tf.Variable(tf.random_normal([5, 5]), name='weight2')\n",
    "W2 = tf.Variable(tf.random_normal([9, 5]), name='weight2')\n",
    "W3 = tf.Variable(tf.random_normal([5, nb_classes]), name='weight3')\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([9]), name='bias1')\n",
    "#b21 = tf.Variable(tf.random_normal([5]), name='bias21')\n",
    "#b22 = tf.Variable(tf.random_normal([5]), name='bias22')\n",
    "b2 = tf.Variable(tf.random_normal([5]), name='bias2')\n",
    "b3 = tf.Variable(tf.random_normal([nb_classes]), name='bias3')\n",
    "\n",
    "with tf.name_scope(\"layer1\") as scope:\n",
    "    layer1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "    layer1 = tf.nn.dropout(layer1, keep_prob=keep_prob)\n",
    "#with tf.name_scope(\"layer21\") as scope:\n",
    "#    layer21 = tf.nn.relu(tf.matmul(layer1, W21) + b21)\n",
    "#    layer21 = tf.nn.dropout(layer21, keep_prob=keep_prob)\n",
    "#with tf.name_scope(\"layer22\") as scope:\n",
    "#    layer22 = tf.nn.relu(tf.matmul(layer21, W22) + b22)\n",
    "#    layer22 = tf.nn.dropout(layer22, keep_prob=keep_prob)\n",
    "\n",
    "#with tf.name_scope(\"layer2\") as scope:\n",
    "#    layer2 = tf.nn.relu(tf.matmul(layer22, W2) + b2)\n",
    "#    layer2 = tf.nn.dropout(layer2, keep_prob=keep_prob)\n",
    "     \n",
    "\n",
    "with tf.name_scope(\"layer2\") as scope:\n",
    "    layer2 = tf.nn.relu(tf.matmul(layer1, W2) + b2)\n",
    "    layer2 = tf.nn.dropout(layer2, keep_prob=keep_prob)\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"last\") as scope:\n",
    "    hypothesis = tf.matmul(layer2, W3) + b3\n",
    "\n",
    "# cost/loss function\n",
    "#cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    " #                      tf.log(1 - hypothesis))\n",
    "#train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "     logits=hypothesis, labels=Y_one_hot))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1.1977545)\n",
      "(100, 0.55777645)\n",
      "(200, 0.53773683)\n",
      "(300, 0.51977378)\n",
      "(400, 0.51090348)\n",
      "(500, 0.49130836)\n",
      "(600, 0.47714728)\n",
      "(700, 0.48259687)\n",
      "(800, 0.47067192)\n",
      "(900, 0.47094625)\n",
      "(1000, 0.47254971)\n",
      "(1100, 0.47016364)\n",
      "(1200, 0.46381128)\n",
      "(1300, 0.46547249)\n",
      "(1400, 0.46706614)\n",
      "(1500, 0.46737289)\n",
      "(1600, 0.46040618)\n",
      "(1700, 0.4586848)\n",
      "(1800, 0.46594965)\n",
      "(1900, 0.45836893)\n",
      "(2000, 0.46407121)\n",
      "(2100, 0.4651463)\n",
      "(2200, 0.45721895)\n",
      "(2300, 0.45690653)\n",
      "(2400, 0.44936803)\n",
      "(2500, 0.45156959)\n",
      "(2600, 0.45737439)\n",
      "(2700, 0.4607946)\n",
      "(2800, 0.4535991)\n",
      "(2900, 0.45708549)\n",
      "(3000, 0.45268762)\n",
      "(3100, 0.46325642)\n",
      "(3200, 0.4634003)\n",
      "(3300, 0.45708182)\n",
      "(3400, 0.45274743)\n",
      "(3500, 0.45875946)\n",
      "(3600, 0.45270535)\n",
      "(3700, 0.45360422)\n",
      "(3800, 0.45959613)\n",
      "(3900, 0.45869863)\n",
      "(4000, 0.45076585)\n",
      "(4100, 0.45490083)\n",
      "(4200, 0.45313355)\n",
      "(4300, 0.4519859)\n",
      "(4400, 0.4580875)\n",
      "(4500, 0.45031086)\n",
      "(4600, 0.45829919)\n",
      "(4700, 0.4564116)\n",
      "(4800, 0.45526928)\n",
      "(4900, 0.45317101)\n",
      "(5000, 0.45301509)\n",
      "(5100, 0.45195985)\n",
      "(5200, 0.45504564)\n",
      "(5300, 0.45572308)\n",
      "(5400, 0.4545438)\n",
      "(5500, 0.45697439)\n",
      "(5600, 0.4513146)\n",
      "(5700, 0.45949611)\n",
      "(5800, 0.45510831)\n",
      "(5900, 0.45363587)\n",
      "(6000, 0.45761853)\n",
      "(6100, 0.4536936)\n",
      "(6200, 0.45071995)\n",
      "(6300, 0.4573383)\n",
      "(6400, 0.45237353)\n",
      "(6500, 0.45068178)\n",
      "(6600, 0.44826594)\n",
      "(6700, 0.45424852)\n",
      "(6800, 0.4500882)\n",
      "(6900, 0.45792431)\n",
      "(7000, 0.44754127)\n",
      "(7100, 0.45115623)\n",
      "(7200, 0.45962721)\n",
      "(7300, 0.45631713)\n",
      "(7400, 0.44561177)\n",
      "(7500, 0.45089185)\n",
      "(7600, 0.45295626)\n",
      "(7700, 0.44790253)\n",
      "(7800, 0.4622699)\n",
      "(7900, 0.45156151)\n",
      "(8000, 0.44779059)\n",
      "(8100, 0.44542614)\n",
      "(8200, 0.44961557)\n",
      "(8300, 0.44876292)\n",
      "(8400, 0.45517448)\n",
      "(8500, 0.45262095)\n",
      "(8600, 0.45218351)\n",
      "(8700, 0.46031001)\n",
      "(8800, 0.45130029)\n",
      "(8900, 0.45167673)\n",
      "(9000, 0.45110765)\n",
      "(9100, 0.45544577)\n",
      "(9200, 0.45301121)\n",
      "(9300, 0.45150551)\n",
      "(9400, 0.4528124)\n",
      "(9500, 0.46348485)\n",
      "(9600, 0.45358998)\n",
      "(9700, 0.45056885)\n",
      "(9800, 0.4507035)\n",
      "(9900, 0.45423859)\n",
      "(10000, 0.45457578)\n",
      "('\\nHypothesis: ', array([[-0.44286782, -0.61690795],\n",
      "       [-0.9523049 ,  0.67768657],\n",
      "       [-0.82008833,  0.7070601 ],\n",
      "       ..., \n",
      "       [-0.44286782, -0.61690795],\n",
      "       [-0.44286782, -0.61690795],\n",
      "       [ 1.68917727,  4.64549828]], dtype=float32), '\\nCorrect: ', array([0, 1, 1, ..., 0, 0, 1]), '\\nAccuracy: ', 0.79980177)\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X: x_train, Y: y_train, keep_prob: 0.7})\n",
    "        #sess.run(train, feed_dict={X: x_train, Y: y_train})\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_train, Y: y_train, keep_prob: 0.7}))\n",
    "            #print(step, sess.run(cost, feed_dict={\n",
    "            #      X: x_data, Y: y_data}))\n",
    "\n",
    "  \n",
    "  # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, prediction, accuracy],\n",
    "                       feed_dict={X: x_test, Y: y_test, keep_prob: 1.0})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
