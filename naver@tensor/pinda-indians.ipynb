{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8) (768, 2)\n"
     ]
    }
   ],
   "source": [
    "input_x = []\n",
    "input_y = []\n",
    "\n",
    "with open(\"./pima-indians-diabetes.csv\",'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        input_x.append(row[:-1])\n",
    "        if row[-1] == 0 :\n",
    "            input_y.append([1,0])\n",
    "        else :\n",
    "            input_y.append([0,1])\n",
    "            \n",
    "input_x = np.array(input_x)\n",
    "input_y = np.array(input_y)\n",
    "\n",
    "print(input_x.shape,input_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03355237  0.82762513  0.40262844 ...,  0.18789327  0.00350622\n",
      "   0.27960308]\n",
      " [ 0.008424    0.71604034  0.55598426 ...,  0.22407851  0.00295683\n",
      "   0.26114412]\n",
      " [ 0.04039768  0.92409698  0.32318146 ...,  0.11765825  0.00339341\n",
      "   0.16159073]\n",
      " ..., \n",
      " [ 0.02691539  0.65135243  0.38758161 ...,  0.14103664  0.00131885\n",
      "   0.16149234]\n",
      " [ 0.00665306  0.83828547  0.39918356 ...,  0.20025708  0.00232192\n",
      "   0.31269379]\n",
      " [ 0.00791454  0.73605211  0.55401772 ...,  0.24060198  0.00249308\n",
      "   0.18203439]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python3_5anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype <U5 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "normalized_x = preprocessing.normalize(input_x)\n",
    "print(normalized_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = normalized_x[:-100]\n",
    "train_y = input_y[:-100]\n",
    "\n",
    "validation_x = normalized_x[-100:]\n",
    "validation_y = input_y[-100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None,8])\n",
    "Y = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "W1 = tf.Variable(tf.random_normal([8, 8]))\n",
    "b1 = tf.Variable(tf.random_normal([8]))\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([8, 2]))\n",
    "b2 = tf.Variable(tf.random_normal([2]))\n",
    "\n",
    "layer = tf.matmul(X, W1) + b1\n",
    "layer = tf.matmul(layer,W2) + b2\n",
    "\n",
    "hypothesis = tf.nn.softmax(layer)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=layer, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "# correct_prediction = tf.equal(tf.cast(hypothesis>0.5, tf.float32), Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "iteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41\n",
      "Accuracy: 0.97\n",
      "Accuracy: 0.97\n",
      "Accuracy: 1.0\n",
      "Accuracy: 1.0\n",
      "Accuracy: 1.0\n",
      "Accuracy: 1.0\n",
      "Accuracy: 1.0\n",
      "Accuracy: 1.0\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(iteration) :\n",
    "    feed_dict = {X: train_x, Y: train_y}\n",
    "    c,_ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "#     print (i,c)\n",
    "    \n",
    "    if i % 100 == 0 :\n",
    "        print('Accuracy:', sess.run(accuracy, feed_dict={X: validation_x, Y: validation_y}))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
