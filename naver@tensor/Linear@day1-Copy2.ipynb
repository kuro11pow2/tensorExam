{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Linear"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 2,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "csvFile = 'pima-indians-diabetes.csv'"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 3,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clip(x, vmin = 1e-7, vmax = 1-1e-7):\n",
    "    return tf.clip_by_value(x, clip_value_max= vmax, clip_value_min= vmin)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 4,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epoch = 1\n",
    "xy = np.loadtxt(csvFile, delimiter=',',dtype='float32')\n",
    "x_data = xy[:,:-1]\n",
    "y_data = xy[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 5,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   6.        ,  148.        ,   72.        ,   35.        ,\n",
       "          0.        ,   33.59999847,    0.62699997,   50.        ], dtype=float32)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 29,
=======
     "execution_count": 5,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[0]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 6,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    mu_x = np.mean(array)\n",
    "    sigma_x = 0\n",
    "    for i in range(len(array)):\n",
    "        sigma_x+=(array[i]-mu_x)*(array[i]-mu_x)\n",
    "    sigma_x/=len(array)\n",
    "    sigma_x = np.sqrt(sigma_x)\n",
    "    return (array-mu_x)/sigma_x"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 7,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63994724 -0.84488499  1.23388028 ...,  0.3429808  -0.84488499\n",
      "  -0.84488499]\n",
      " [ 0.84832382 -1.1233964   1.94372392 ...,  0.00330087  0.1597866\n",
      "  -0.87301922]\n",
      " [ 0.14964074 -0.16054574 -0.26394123 ...,  0.14964074 -0.47073221\n",
      "   0.04624525]\n",
      " ..., \n",
      " [ 0.20401253 -0.68442196 -1.10325563 ..., -0.73518956 -0.24020459\n",
      "  -0.2021289 ]\n",
      " [ 0.46849191 -0.36506069  0.6043973  ..., -0.6851933  -0.37110096\n",
      "  -0.47378501]\n",
      " [ 1.42599523 -0.19067201 -0.10558426 ..., -0.27575976  1.17073202\n",
      "  -0.87137401]] [[ 0.63994724  0.84832382  0.14964074 ...,  0.20401253  0.46849191\n",
      "   1.42599523]\n",
      " [-0.84488499 -1.1233964  -0.16054574 ..., -0.68442196 -0.36506069\n",
      "  -0.19067201]\n",
      " [ 1.23388028  1.94372392 -0.26394123 ..., -1.10325563  0.6043973\n",
      "  -0.10558426]\n",
      " ..., \n",
      " [ 0.3429808   0.00330087  0.14964074 ..., -0.73518956 -0.6851933\n",
      "  -0.27575976]\n",
      " [-0.84488499  0.1597866  -0.47073221 ..., -0.24020459 -0.37110096\n",
      "   1.17073202]\n",
      " [-0.84488499 -0.87301922  0.04624525 ..., -0.2021289  -0.47378501\n",
      "  -0.87137401]]\n"
     ]
    }
   ],
   "source": [
    "x_data_transpose = np.transpose(x_data, [1, 0])\n",
    "for i in range(len(x_data_transpose)):\n",
    "    x_data_transpose[i] = normalize(x_data_transpose[i])\n",
    "x_data_normalize = np.transpose(x_data_transpose)\n",
    "print(x_data_transpose, x_data)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
=======
   "execution_count": 8,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 32,
=======
     "execution_count": 8,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_normalize.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": 9,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63994724,  0.84832382,  0.14964074,  0.9072699 , -0.69289052,\n",
       "        0.20401253,  0.46849191,  1.42599523], dtype=float32)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 33,
=======
     "execution_count": 9,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_normalize[0]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
=======
   "execution_count": 11,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = {}\n",
    "test_data = {}\n",
    "train_data['input'] = x_data_normalize[:600]\n",
    "train_data['output'] = y_data[:600]\n",
    "test_data['input'] = x_data_normalize[600:]\n",
    "test_data['output'] = y_data[600:]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
=======
   "execution_count": 12,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_shape(dataset):\n",
    "    print(\"input data shape : {}, output_data shape : {}\".format(dataset['input'].shape, dataset['output'].shape))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
=======
   "execution_count": 13,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data shape : (600, 8), output_data shape : (600, 1)\n",
      "input data shape : (168, 8), output_data shape : (168, 1)\n"
     ]
    }
   ],
   "source": [
    "print_shape(train_data)\n",
    "print_shape(test_data)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
=======
   "execution_count": 14,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nfeatures = x_data.shape[1]\n",
    "nclasses = y_data.shape[1]\n",
    "# mean, var = tf.nn.moments(x=tf.constant(x_data[0]), axes=[0])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 29,
   "metadata": {},
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, nfeatures], name=\"input\")\n",
    "Y = tf.placeholder(tf.float32, [None, nclasses], name=\"output\")\n",
    "\n",
    "W = tf.Variable(tf.random_normal([nfeatures, 8]), name = 'weights')\n",
    "b = tf.Variable(tf.random_normal([8], name='bias'))\n",
    "\n",
<<<<<<< HEAD
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "# hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sigmoid_2:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis"
=======
    "\n",
    "\n",
    "W_2 = tf.Variable(tf.random_normal([8, nclasses]), name = 'weights_2')\n",
    "b_2 = tf.Variable(tf.random_normal([nclasses], name = 'bias2'))\n",
    "\n",
    "layer = tf.matmul(X,W) + b\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer, W_2) + b_2)"
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": 30,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(clip(hypothesis)) + (1 - Y) * tf.log(clip(1 - hypothesis)))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 31,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.cast(hypothesis>0.5, tf.float32), Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 32,
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "accuracy 0.4464285671710968\n",
      "0 step cost 1.3556880950927734 accuracy 0.4464285671710968\n",
      "500 step cost 0.7256587743759155 accuracy 0.601190447807312\n",
      "1000 step cost 0.5606140494346619 accuracy 0.7321428656578064\n",
      "1500 step cost 0.5052377581596375 accuracy 0.761904776096344\n",
      "2000 step cost 0.4857369065284729 accuracy 0.773809552192688\n",
      "2500 step cost 0.4787289500236511 accuracy 0.773809552192688\n",
      "3000 step cost 0.47605448961257935 accuracy 0.7678571343421936\n",
      "3500 step cost 0.4749510586261749 accuracy 0.773809552192688\n",
      "4000 step cost 0.4744640588760376 accuracy 0.773809552192688\n",
      "4500 step cost 0.47423848509788513 accuracy 0.773809552192688\n",
      "5000 step cost 0.4741307199001312 accuracy 0.773809552192688\n",
      "5500 step cost 0.47407805919647217 accuracy 0.773809552192688\n",
      "6000 step cost 0.47405192255973816 accuracy 0.773809552192688\n",
      "6500 step cost 0.4740388095378876 accuracy 0.773809552192688\n",
      "7000 step cost 0.4740324020385742 accuracy 0.773809552192688\n",
      "7500 step cost 0.47402897477149963 accuracy 0.773809552192688\n",
      "8000 step cost 0.47402724623680115 accuracy 0.773809552192688\n",
      "8500 step cost 0.47402650117874146 accuracy 0.773809552192688\n",
      "9000 step cost 0.47402599453926086 accuracy 0.773809552192688\n",
      "9500 step cost 0.47402578592300415 accuracy 0.773809552192688\n",
      "10000 step cost 0.4740257263183594 accuracy 0.773809552192688\n",
      "10500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "11000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "11500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "12000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "12500 step cost 0.4740254580974579 accuracy 0.773809552192688\n",
      "13000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "13500 step cost 0.4740254580974579 accuracy 0.773809552192688\n",
      "14000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "14500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "15000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "15500 step cost 0.4740253686904907 accuracy 0.773809552192688\n",
      "16000 step cost 0.4740254580974579 accuracy 0.773809552192688\n",
      "16500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "17000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "17500 step cost 0.4740254580974579 accuracy 0.773809552192688\n",
      "18000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "18500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "19000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "19500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "20000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "20500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "21000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "21500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "22000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "22500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "23000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "23500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "24000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "24500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "25000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "25500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "26000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "26500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "27000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "27500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "28000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "28500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "29000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "29500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "30000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "30500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "31000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "31500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "32000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "32500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "33000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "33500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "34000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "34500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "35000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "35500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "36000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "36500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "37000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "37500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "38000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "38500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "39000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "39500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "40000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "40500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "41000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "41500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "42000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "42500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "43000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "43500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "44000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "44500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "45000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "45500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "46000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "46500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "47000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "47500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "48000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "48500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "49000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "49500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "50000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "50500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "51000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "51500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "52000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "52500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "53000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "53500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "54000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "54500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "55000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "55500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "56000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "56500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "57000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "57500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "58000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "58500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "59000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "59500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "60000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "60500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "61000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "61500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "62000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "62500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "63000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "63500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "64000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "64500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "65000 step cost 0.47402551770210266 accuracy 0.773809552192688\n"
=======
      "accuracy 0.4226190447807312\n",
      "0 step cost 3.036928415298462 accuracy 0.4285714328289032\n",
      "500 step cost 0.47427433729171753 accuracy 0.7857142686843872\n",
      "1000 step cost 0.4740258753299713 accuracy 0.773809552192688\n",
      "1500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "2000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "2500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "3000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "3500 step cost 0.4740254580974579 accuracy 0.773809552192688\n",
      "4000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "4500 step cost 0.4740254580974579 accuracy 0.773809552192688\n",
      "5000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "5500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "6000 step cost 0.4740254580974579 accuracy 0.773809552192688\n",
      "6500 step cost 0.4740254282951355 accuracy 0.773809552192688\n",
      "7000 step cost 0.4740254282951355 accuracy 0.773809552192688\n",
      "7500 step cost 0.4740254282951355 accuracy 0.773809552192688\n",
      "8000 step cost 0.4740254282951355 accuracy 0.773809552192688\n",
      "8500 step cost 0.4740254580974579 accuracy 0.773809552192688\n",
      "9000 step cost 0.4740254580974579 accuracy 0.773809552192688\n",
      "9500 step cost 0.4740254580974579 accuracy 0.773809552192688\n",
      "10000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "10500 step cost 0.4740254580974579 accuracy 0.773809552192688\n",
      "11000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "11500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "12000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "12500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "13000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "13500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "14000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "14500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "15000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "15500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "16000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "16500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "17000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "17500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "18000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "18500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "19000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "19500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "20000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "20500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "21000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "21500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "22000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "22500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "23000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "23500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "24000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "24500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "25000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "25500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "26000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "26500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "27000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "27500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "28000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "28500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "29000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "29500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "30000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "30500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "31000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "31500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "32000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "32500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "33000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "33500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "34000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "34500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "35000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "35500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "36000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "36500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "37000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "37500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "38000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "38500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "39000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "39500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "40000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "40500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "41000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "41500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "42000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "42500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "43000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "43500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "44000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "44500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "45000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "45500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "46000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "46500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "47000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "47500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "48000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "48500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "49000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "49500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "50000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "50500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "51000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "51500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "52000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "52500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "53000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "53500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "54000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "54500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "55000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "55500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "56000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "56500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "57000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "57500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "58000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "58500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "59000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "59500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "60000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "60500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "61000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "61500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "62000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "62500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "63000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "63500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "64000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "64500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "65000 step cost 0.47402557730674744 accuracy 0.773809552192688\n"
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "65500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "66000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "66500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "67000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "67500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "68000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "68500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "69000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "69500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "70000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "70500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "71000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "71500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "72000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "72500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "73000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "73500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "74000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "74500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "75000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "75500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "76000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "76500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "77000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "77500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "78000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "78500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "79000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "79500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "80000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "80500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "81000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "81500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "82000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "82500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "83000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "83500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "84000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "84500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "85000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "85500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "86000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "86500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "87000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "87500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "88000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "88500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "89000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "89500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "90000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "90500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "91000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "91500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "92000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "92500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "93000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "93500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "94000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "94500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "95000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "95500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "96000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "96500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "97000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "97500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "98000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "98500 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "99000 step cost 0.47402551770210266 accuracy 0.773809552192688\n",
      "99500 step cost 0.47402551770210266 accuracy 0.773809552192688\n"
=======
      "65500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "66000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "66500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "67000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "67500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "68000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "68500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "69000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "69500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "70000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "70500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "71000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "71500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "72000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "72500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "73000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "73500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "74000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "74500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "75000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "75500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "76000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "76500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "77000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "77500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "78000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "78500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "79000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "79500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "80000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "80500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "81000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "81500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "82000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "82500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "83000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "83500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "84000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "84500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "85000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "85500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "86000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "86500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "87000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "87500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "88000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "88500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "89000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "89500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "90000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "90500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "91000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "91500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "92000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "92500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "93000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "93500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "94000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "94500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "95000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "95500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "96000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "96500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "97000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "97500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "98000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "98500 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "99000 step cost 0.47402557730674744 accuracy 0.773809552192688\n",
      "99500 step cost 0.47402557730674744 accuracy 0.773809552192688\n"
>>>>>>> 1ae069bca7952e545fe1f9c3d85f1cee73e38c74
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "atemp = sess.run(accuracy, feed_dict = {X : test_data['input'], Y : test_data['output']})\n",
    "print(\"accuracy {}\".format(atemp))\n",
    "\n",
    "for i in range(epoch):\n",
    "    for step in range(100000):\n",
    "        opt, cc = sess.run([train,cost], feed_dict={X:train_data['input'], Y:train_data['output']})\n",
    "        if step%500 ==0:\n",
    "            atemp = sess.run(accuracy, feed_dict = {X : test_data['input'], Y : test_data['output']})\n",
    "            print(\"{} step cost {} accuracy {}\".format(step, cc, atemp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_hypothesis(input_):\n",
    "    return sess.run(hypothesis, feed_dict = {X : np.reshape(input_, [-1, nfeatures])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.51050395]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hypothesis(test_data['input'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['output'][8]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
