{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "csvFile = 'pima-indians-diabetes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'> <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.00005\n",
    "epoch = 1\n",
    "batch_size = 1\n",
    "filename_queue = tf.train.string_input_producer([csvFile])\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "record_defaults = [[1.], [1.], [1.], [1.], [1.], [1.], [1.], [1.], [1]]\n",
    "\n",
    "features = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "X_data = features[:-1]\n",
    "Y_data = features[-1:]\n",
    "# batch_xs, label = tf.train.shuffle_batch(tensors=[X_data, Y_data], batch_size=batch_size,\n",
    "#                                          num_threads=1,\n",
    "#                                          capacity=5000,\n",
    "#                                          min_after_dequeue=100)\n",
    "batch_xs, label = tf.train.batch(tensors=[X_data, Y_data], batch_size=batch_size)\n",
    "label = tf.one_hot(label, depth=2) # 0 => [1,0] 1 => [0,1]\n",
    "label = tf.reshape(label,[-1,2])\n",
    "features = len(X_data)\n",
    "classes = 2\n",
    "print(type(features), type(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"output_5:0\", shape=(?, 2), dtype=float32) Tensor(\"Softmax_5:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, features], name=\"input\")\n",
    "Y = tf.placeholder(tf.float32, [None, classes], name=\"output\")\n",
    "\n",
    "W = tf.Variable(tf.random_normal([features, classes]))\n",
    "b = tf.Variable(tf.random_normal([classes], name='bias'))\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "print(Y,hypothesis)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "correct_prediction = tf.equal(tf.arg_max(hypothesis,1), tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 42.9783 0.0\n",
      "20 nan 0.0\n",
      "40 nan 1.0\n",
      "60 nan 0.0\n",
      "80 nan 0.0\n",
      "100 nan 0.0\n",
      "120 nan 0.0\n",
      "140 nan 1.0\n",
      "160 nan 0.0\n",
      "180 nan 1.0\n",
      "200 nan 1.0\n",
      "220 nan 1.0\n",
      "240 nan 1.0\n",
      "260 nan 1.0\n",
      "280 nan 1.0\n",
      "300 nan 1.0\n",
      "320 nan 0.0\n",
      "340 nan 1.0\n",
      "360 nan 0.0\n",
      "380 nan 1.0\n",
      "400 nan 1.0\n",
      "420 nan 1.0\n",
      "440 nan 0.0\n",
      "460 nan 1.0\n",
      "480 nan 0.0\n",
      "500 nan 1.0\n",
      "520 nan 1.0\n",
      "540 nan 0.0\n",
      "560 nan 1.0\n",
      "580 nan 1.0\n",
      "600 nan 1.0\n",
      "620 nan 1.0\n",
      "640 nan 0.0\n",
      "660 nan 1.0\n",
      "680 nan 0.0\n",
      "700 nan 1.0\n",
      "720 nan 1.0\n",
      "740 nan 1.0\n",
      "760 nan 1.0\n",
      "780 nan 1.0\n",
      "800 nan 1.0\n",
      "820 nan 0.0\n",
      "840 nan 0.0\n",
      "860 nan 1.0\n",
      "880 nan 1.0\n",
      "900 nan 0.0\n",
      "920 nan 0.0\n",
      "940 nan 1.0\n",
      "960 nan 1.0\n",
      "980 nan 1.0\n",
      "1000 nan 1.0\n",
      "1020 nan 1.0\n",
      "1040 nan 1.0\n",
      "1060 nan 0.0\n",
      "1080 nan 1.0\n",
      "1100 nan 0.0\n",
      "1120 nan 1.0\n",
      "1140 nan 0.0\n",
      "1160 nan 1.0\n",
      "1180 nan 0.0\n",
      "1200 nan 0.0\n",
      "1220 nan 0.0\n",
      "1240 nan 0.0\n",
      "1260 nan 1.0\n",
      "1280 nan 0.0\n",
      "1300 nan 0.0\n",
      "1320 nan 1.0\n",
      "1340 nan 1.0\n",
      "1360 nan 1.0\n",
      "1380 nan 1.0\n",
      "1400 nan 1.0\n",
      "1420 nan 0.0\n",
      "1440 nan 1.0\n",
      "1460 nan 1.0\n",
      "1480 nan 0.0\n",
      "1500 nan 1.0\n",
      "1520 nan 1.0\n",
      "1540 nan 0.0\n",
      "1560 nan 0.0\n",
      "1580 nan 1.0\n",
      "1600 nan 0.0\n",
      "1620 nan 1.0\n",
      "1640 nan 0.0\n",
      "1660 nan 0.0\n",
      "1680 nan 1.0\n",
      "1700 nan 1.0\n",
      "1720 nan 1.0\n",
      "1740 nan 1.0\n",
      "1760 nan 1.0\n",
      "1780 nan 1.0\n",
      "1800 nan 1.0\n",
      "1820 nan 0.0\n",
      "1840 nan 1.0\n",
      "1860 nan 1.0\n",
      "1880 nan 0.0\n",
      "1900 nan 1.0\n",
      "1920 nan 0.0\n",
      "1940 nan 0.0\n",
      "1960 nan 1.0\n",
      "1980 nan 0.0\n",
      "2000 nan 0.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        for step in range(2001):\n",
    "            opt, cc = sess.run([optimizer,cost], feed_dict={X:batch_xs.eval(), Y:label.eval()})\n",
    "    #         print(batch_xs.eval(),label.eval())\n",
    "            if step%20 ==0:\n",
    "                atemp = accuracy.eval({X:batch_xs.eval(), Y:label.eval()})\n",
    "                \n",
    "                print(step, cc, atemp)\n",
    "    \n",
    "#     opt, cc,hy = sess.run([optimizer,cost, hypothesis], feed_dict={X:batch_xs.eval(), Y:label.eval()})\n",
    "#     print(batch_xs.eval(),W.eval(),hy)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
